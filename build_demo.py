#!/usr/bin/env python3
"""
build_demo.py

ì‹¤ì œ ë°ì´í„°(data_urbert)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Type A / Type B ë°ëª¨ ì‹¤í—˜ì„ ìë™ êµ¬ì„±í•©ë‹ˆë‹¤.

ìˆ˜í–‰í•˜ëŠ” ì‘ì—…:
  1. output_samples/ ì—ì„œ ëª¨ë¸ ëª©ë¡ ìŠ¤ìº”
  2. tts_metadata/ ì—ì„œ í…ìŠ¤íŠ¸ ë§¤í•‘ ë¡œë“œ
  3. ì–¸ì–´ë³„ë¡œ ê³µí†µ ìƒ˜í”Œ ID 10ê°œ ì„ íƒ (5â†’A, 5â†’B)
  4. ì˜¤ë””ì˜¤ íŒŒì¼ ì‹¬ë³¼ë¦­ ë§í¬ ìƒì„±
  5. config.js ìë™ ìƒì„±

ì‚¬ìš©ë²•:
  cd /home/woongzip/homepage/ur-bert-eval
  python build_demo.py
"""

import os
import csv
import json
import random
import glob
from pathlib import Path
from datetime import datetime
from collections import defaultdict

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SETTINGS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DATA_ROOT = "/home/woongzip/data_urbert"
SAMPLES_DIR = os.path.join(DATA_ROOT, "output_samples")
METADATA_DIR = os.path.join(DATA_ROOT, "tts_metadata")

OUTPUT_DIR_A = "/home/woongzip/homepage/ur-bert-eval/A"
OUTPUT_DIR_B = "/home/woongzip/homepage/ur-bert-eval/B"

SAMPLES_PER_LANG = 10   # ì–¸ì–´ë‹¹ ìƒ˜í”Œ ìˆ˜ (5â†’A, 5â†’B)
SPLIT_INDEX = 5          # ì• 5ê°œâ†’A, ë’¤ 5ê°œâ†’B
RANDOM_SEED = 42

SHEET_URL = "https://script.google.com/macros/s/AKfycby6_3EvfoU0mcQg2IzBdmhLFlAPIn3XBzpfNbuuBigz-LWUwX3CgYMWBANXTHHSLa-umQ/exec"

# ëª¨ë¸ëª… suffix â†’ metadata CSVì˜ lang code
LANG_MAP = {
    "AF": "af",
    "DE": "de",
    "EN": "en",
    "NP": "np",
    "SI": "si",
    "TN": "tn",
    "ZH": "zh",
    "KM": "km",
    "JV": "jv",
    "SU": "su",
    "XH": "xh",
}

# ì–¸ì–´ ì½”ë“œ â†’ í‘œì‹œìš© ì´ë¦„
LANG_DISPLAY = {
    "af": "Afrikaans",
    "de": "German",
    "en": "English",
    "np": "Nepali",
    "si": "Sinhala",
    "tn": "Tswana",
    "zh": "Chinese",
    "km": "Khmer",
    "jv": "Javanese",
    "su": "Sundanese",
    "xh": "Xhosa",
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def get_model_lang(model_name):
    """ëª¨ë¸ëª…ì—ì„œ ì–¸ì–´ ì½”ë“œ ì¶”ì¶œ (ì˜ˆ: URBERT-TN â†’ tn)"""
    suffix = model_name.split("-")[-1]
    return LANG_MAP.get(suffix, None)


def get_checkpoint_dir(model_path):
    """ëª¨ë¸ í´ë” ë‚´ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°"""
    dirs = [d for d in os.listdir(model_path)
            if os.path.isdir(os.path.join(model_path, d))]
    if not dirs:
        return None
    return dirs[0]  # G_100000 or G_300000 ë“±


def load_metadata(lang_code):
    """metadata CSVì—ì„œ {id: text} ë”•ì…”ë„ˆë¦¬ ë°˜í™˜"""
    csv_path = os.path.join(METADATA_DIR, f"{lang_code}_test.csv")
    if not os.path.exists(csv_path):
        print(f"  âš  Metadata not found: {csv_path}")
        return {}

    id_to_text = {}
    with open(csv_path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f, delimiter="|")
        for row in reader:
            id_to_text[row["id"]] = row["text"]
    return id_to_text


def get_wav_ids(model_path, ckpt_dir):
    """ëª¨ë¸ì˜ generated_wav í´ë”ì—ì„œ wav íŒŒì¼ ID ëª©ë¡ ë°˜í™˜"""
    wav_dir = os.path.join(model_path, ckpt_dir, "generated_wav")
    if not os.path.exists(wav_dir):
        return set()
    return {os.path.splitext(f)[0] for f in os.listdir(wav_dir) if f.endswith(".wav")}


def main():
    random.seed(RANDOM_SEED)

    # â”€â”€â”€ Step 1: ëª¨ë¸ ìŠ¤ìº” & ì–¸ì–´ë³„ ê·¸ë£¹í•‘ â”€â”€â”€
    print("ğŸ“‚ Scanning models...")
    all_models = sorted([
        d for d in os.listdir(SAMPLES_DIR)
        if os.path.isdir(os.path.join(SAMPLES_DIR, d))
    ])

    # ëª¨ë¸ë³„ ì •ë³´ ìˆ˜ì§‘
    model_info = {}  # {model_name: {lang, ckpt_dir, wav_ids, wav_dir}}
    lang_to_models = defaultdict(list)

    for model_name in all_models:
        lang = get_model_lang(model_name)
        if lang is None:
            print(f"  âš  Unknown language for model: {model_name}, skipping")
            continue

        model_path = os.path.join(SAMPLES_DIR, model_name)
        ckpt_dir = get_checkpoint_dir(model_path)
        if ckpt_dir is None:
            print(f"  âš  No checkpoint dir for model: {model_name}, skipping")
            continue

        wav_ids = get_wav_ids(model_path, ckpt_dir)
        wav_dir = os.path.join(model_path, ckpt_dir, "generated_wav")

        model_info[model_name] = {
            "lang": lang,
            "ckpt_dir": ckpt_dir,
            "wav_ids": wav_ids,
            "wav_dir": wav_dir,
        }
        lang_to_models[lang].append(model_name)
        print(f"  âœ“ {model_name} ({lang}) - {len(wav_ids)} wavs")

    print(f"\n  Total: {len(model_info)} models, {len(lang_to_models)} languages")

    # â”€â”€â”€ Step 2: ì–¸ì–´ë³„ë¡œ ê³µí†µ ìƒ˜í”Œ ì„ íƒ â”€â”€â”€
    print("\nğŸ¯ Selecting samples per language...")
    lang_selected = {}  # {lang: [list of 10 sample IDs]}

    for lang, models in sorted(lang_to_models.items()):
        # í•´ë‹¹ ì–¸ì–´ì˜ ëª¨ë“  ëª¨ë¸ì— ê³µí†µìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” sample ID ì°¾ê¸°
        common_ids = None
        for model_name in models:
            ids = model_info[model_name]["wav_ids"]
            if common_ids is None:
                common_ids = ids.copy()
            else:
                common_ids &= ids

        # metadataì—ë„ ì¡´ì¬í•˜ëŠ” IDë§Œ í•„í„°
        metadata = load_metadata(lang)
        common_ids = {sid for sid in common_ids if sid in metadata}

        if len(common_ids) < SAMPLES_PER_LANG:
            print(f"  âš  {lang}: only {len(common_ids)} common samples (need {SAMPLES_PER_LANG})")
            selected = sorted(common_ids)[:SAMPLES_PER_LANG]
        else:
            selected = sorted(random.sample(sorted(common_ids), SAMPLES_PER_LANG))

        lang_selected[lang] = selected
        display_name = LANG_DISPLAY.get(lang, lang)
        print(f"  âœ“ {lang} ({display_name}): {len(selected)} samples from {len(models)} models")

    # â”€â”€â”€ Step 3: Stimuli ìƒì„± & A/B ë¶„í•  â”€â”€â”€
    print("\nğŸ“‹ Building stimuli...")
    stimuli_a = []
    stimuli_b = []

    for model_name in sorted(model_info.keys()):
        info = model_info[model_name]
        lang = info["lang"]
        metadata = load_metadata(lang)
        selected_ids = lang_selected.get(lang, [])

        for si, sample_id in enumerate(selected_ids):
            text = metadata.get(sample_id, f"[{sample_id}]")
            wav_filename = f"{sample_id}.wav"

            stimulus = {
                "id": f"{model_name}_{si+1:02d}",
                "model": model_name,
                "lang": lang,
                "text": text,
                "roman": "(Roman transcription TBD)",  # ì¶”í›„ ì¶”ê°€
                "audio": f"./samples/{model_name}/{wav_filename}",
                "_wav_src": os.path.join(info["wav_dir"], wav_filename),  # symlinkìš© (configì—ëŠ” ì•ˆ ë“¤ì–´ê°)
            }

            if si < SPLIT_INDEX:
                stimuli_a.append(stimulus)
            else:
                stimuli_b.append(stimulus)

    print(f"  Type A: {len(stimuli_a)} stimuli")
    print(f"  Type B: {len(stimuli_b)} stimuli")

    # â”€â”€â”€ Step 4: ì‹¬ë³¼ë¦­ ë§í¬ ìƒì„± â”€â”€â”€
    print("\nğŸ”— Creating audio symlinks...")
    for label, output_dir, stimuli_list in [("A", OUTPUT_DIR_A, stimuli_a),
                                             ("B", OUTPUT_DIR_B, stimuli_b)]:
        link_count = 0
        for stim in stimuli_list:
            wav_src = stim["_wav_src"]
            # samples/{MODEL_NAME}/filename.wav
            model_name = stim["model"]
            wav_filename = os.path.basename(wav_src)
            dest_dir = os.path.join(output_dir, "samples", model_name)
            os.makedirs(dest_dir, exist_ok=True)

            dest_path = os.path.join(dest_dir, wav_filename)
            if os.path.exists(dest_path) or os.path.islink(dest_path):
                os.remove(dest_path)
            os.symlink(wav_src, dest_path)
            link_count += 1

        print(f"  Type {label}: {link_count} symlinks in {output_dir}/samples/")

    # â”€â”€â”€ Step 5: config.js ìƒì„± â”€â”€â”€
    print("\nğŸ“ Generating config.js files...")

    for label, output_dir, stimuli_list, storage_key in [
        ("A", OUTPUT_DIR_A, stimuli_a, "urbert_eval_A"),
        ("B", OUTPUT_DIR_B, stimuli_b, "urbert_eval_B"),
    ]:
        # _wav_src í•„ë“œ ì œê±° (config.jsì— ë¶ˆí•„ìš”)
        clean_stimuli = []
        for s in stimuli_list:
            clean = {k: v for k, v in s.items() if not k.startswith("_")}
            clean_stimuli.append(clean)

        stimuli_json = json.dumps(clean_stimuli, ensure_ascii=False, indent=2)

        config_content = f"""/**
 * UR-BERT Multilingual TTS MOS Evaluation - Auto-generated Config
 * Type: {label}
 * Generated: {datetime.now().isoformat()}
 * Models: {len(model_info)}, Stimuli: {len(clean_stimuli)}
 */

const EVAL_CONFIG = {{
  title: "UR-BERT Multilingual TTS Evaluation",
  experimentType: "{label}",
  itemsPerPage: 10,
  storageKey: "{storage_key}",
  sheetUrl: "{SHEET_URL}"
}};

const stimuli = {stimuli_json};
"""

        output_file = os.path.join(output_dir, "config.js")
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(config_content)
        print(f"  âœ“ {output_file} ({len(clean_stimuli)} stimuli)")

    # â”€â”€â”€ Summary â”€â”€â”€
    print("\n" + "=" * 60)
    print("âœ… Demo experiment built successfully!")
    print(f"   Models: {len(model_info)}")
    print(f"   Languages: {len(lang_to_models)}")
    print(f"   Type A: {len(stimuli_a)} stimuli â†’ {OUTPUT_DIR_A}/")
    print(f"   Type B: {len(stimuli_b)} stimuli â†’ {OUTPUT_DIR_B}/")
    print()
    print("ğŸš€ ë¡œì»¬ í…ŒìŠ¤íŠ¸ ë°©ë²•:")
    print(f"   cd {OUTPUT_DIR_A}")
    print(f"   python3 -m http.server 8080")
    print(f"   â†’ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8080 ì ‘ì†")
    print()
    print(f"   cd {OUTPUT_DIR_B}")
    print(f"   python3 -m http.server 8081")
    print(f"   â†’ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8081 ì ‘ì†")
    print("=" * 60)


if __name__ == "__main__":
    main()
